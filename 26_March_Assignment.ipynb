{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a317df4",
   "metadata": {},
   "source": [
    "## Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2c1423",
   "metadata": {},
   "source": [
    "A1. Simple linear regression involves predicting a dependent variable based on a single independent variable, while multiple linear regression involves predicting a dependent variable based on multiple independent variables. \n",
    "\n",
    "Example of simple linear regression: Predicting a person's weight (dependent variable) based on their height (independent variable).\n",
    "\n",
    "Example of multiple linear regression: Predicting a house price (dependent variable) based on variables like size, number of bedrooms, and location (multiple independent variables).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd9e35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32c16f64",
   "metadata": {},
   "source": [
    "## Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold ina given dataset?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea96544",
   "metadata": {},
   "source": [
    "A2. Assumptions of linear regression include linearity, independence of errors, homoscedasticity (constant variance of errors), normality of errors, and absence of multicollinearity. These assumptions can be checked through visual analysis of residuals, tests for normality, examining scatter plots, correlation matrices for multicollinearity, and other statistical tests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eeb2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cff90101",
   "metadata": {},
   "source": [
    "## Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaeb3a0",
   "metadata": {},
   "source": [
    "A3. In a linear regression model, the slope represents the change in the dependent variable for each unit change in the independent variable. It quantifies the relationship between the variables. The intercept represents the predicted value of the dependent variable when the independent variable is zero. \n",
    "\n",
    "Example: In a linear regression model predicting sales (dependent variable) based on advertising spend (independent variable), the slope indicates the increase in sales for each additional unit of advertising spend, and the intercept represents the predicted sales when there is zero advertising spend.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e0fba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c02a2e0a",
   "metadata": {},
   "source": [
    "## Q4. Explain the concept of gradient descent. How is it used in machine learning? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061e149d",
   "metadata": {},
   "source": [
    "A4. Gradient descent is an optimization algorithm used in machine learning to minimize the error of a model. It iteratively adjusts the model's parameters based on the gradients of the loss function. The algorithm starts with initial parameter values and updates them in the direction of steepest descent to find the optimal values that minimize the loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf33b40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "711180b4",
   "metadata": {},
   "source": [
    "## Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77e9f63",
   "metadata": {},
   "source": [
    "A5. Multiple linear regression is an extension of simple linear regression that involves predicting a dependent variable based on multiple independent variables. It considers the simultaneous effect of multiple predictors on the target variable. This model can capture more complex relationships and provide more detailed insights into the relationships between variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35edf7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc04af60",
   "metadata": {},
   "source": [
    "## Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd461717",
   "metadata": {},
   "source": [
    "A6. Multicollinearity in multiple linear regression occurs when independent variables are highly correlated with each other. It can lead to unstable estimates of the regression coefficients and difficulty in interpreting the individual effects of variables. Multicollinearity can be detected through correlation matrices or variance inflation factor (VIF) analysis. To address this issue, potential solutions include removing one of the correlated variables, combining correlated variables into a single variable, or using dimensionality reduction techniques like principal component analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2f2fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea7df276",
   "metadata": {},
   "source": [
    "## Q7. Describe the polynomial regression model. How is it different from linear regression?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b409328",
   "metadata": {},
   "source": [
    "A7. Polynomial regression is a type of regression analysis where the relationship between the dependent variable and the independent variable(s) is modeled as an nth-degree polynomial function. It allows for curved relationships between variables, whereas linear regression assumes a linear relationship. Polynomial regression can capture more complex patterns and non-linear trends in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd475bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "629c8d52",
   "metadata": {},
   "source": [
    "## Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b7f0d",
   "metadata": {},
   "source": [
    "A8. The advantages of polynomial regression include its ability to model non-linear relationships, flexibility in capturing complex patterns, and potential for higher predictive accuracy. However, polynomial regression can be prone to overfitting, especially with higher polynomial degrees. It can also be more computationally expensive and may require more data to estimate the parameters accurately. Polynomial regression is preferred when there is prior knowledge or evidence of non-linear relationships between variables and when the additional complexity outweighs the risk of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b33989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
